# A-Star-Search

This project is a demonstration on an algorithm called Repeated Forward A* Search. Repeated Forward A* Search uses a heuristic to estimate the distance between its current state and the desired end state. This prediction is used by algorithm to make future pathing decisions and reach the end state with the shortest possible path. Repeated Forward A* Search has comparable or superior efficiency compared to most other derivatives of A* search. The robot used in this algorithm measures the heuristic with an "f value", which is calculated by the cost of the getting to the current state added to the heursitic of the end goal. A* search always prefers paths with lower f values, which means the robot will choose paths that are closer to the start and goal over erroneous paths. If the robot runs into a deadend, it can restart the algorithm and will continue seeking out paths that will optimize its distance from the start and goal points. Considering the heuristic, the robot will continue mapping walls blocking it from lowering its f value and reaching the goal state. If it is not possible to reach the goal state, the robot will map every wall blocking it from lowering its f value and reaching the goal state: it can determine it’s impossible to reach the goal state from this information. If reaching the goal state is possible the robot may encounter deadends or walls blocking the path, but eventually since its programmed to stay along a path with low f values it will find a common path between the start and goal states. The maximum amount of moves being bounded by the number of unblocked cells squared means it's bounded by the number of unblocked cells being the average amount each cell is visited. For example, if there are 7 unblocked cells in a grid, the upper move bound would be on average each cell would be visited 7 times.

The least efficient scenario possible is if there is no possible path and the robot initially traversed to the furthest possible node next to an unknown wall, then backtracked to the start cell. And the robot kept going to the node next to the furthest possible wall to learn of it, then backtracking to the start until every blocking wall was discovered. It’s impossible for this scenario to reach the ceiling since although the common backtracking route will be travelled multiple times, the cells adjacent to the walls will not since A* search will avoid traversing the same blocked paths twice

The efficiency of Backwards Repeated A* search compared to Forward Repeated A* search and vice versa is dependent on whether the start state or the goal state has more walls around their location. It is always more efficient to start at the point that has the most walls. If an algorithm starts in a relatively open area and has to go through a walled area to reach the goal, then the value of the entrance of the walled area will almost always be higher than some cell in the open area on the stack. This causes the A* search algorithm to process nearly every cell in the open area until there are no more smaller f values, then it will finally expand into what is in the closed wall. This is opposed to starting in the more heavily walled area, where the algorithm usually has to process far fewer cells before going into the more open area. And in the open area, the heuristic will guide the robot directly to the goal, usually going around a few walls in the process. If there are no walls at all, the efficiency of both is always identical. 

